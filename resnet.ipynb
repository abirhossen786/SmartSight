{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0cWuAZoI5WhyRB1J7dAnx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abirhossen786/SmartSight/blob/main/resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5BhSs3ta8Zn",
        "outputId": "11de788d-895f-4712-c345-93a0b06fed22"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (56.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGkkZr7jbDNh",
        "outputId": "644903a6-26ab-4056-9996-e79de2ba4d11"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, ZeroPadding2D, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, BatchNormalization\n",
        "!pip install tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow_model_optimization import *\n",
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\r\u001b[K     |██                              | 10kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (0.1.6)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.19.5)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQDQGsD8bNTd",
        "outputId": "8df84536-d20c-48a6-dcdf-718ed4db96cd"
      },
      "source": [
        "(trainX, trainy), (testX, testy) = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1dtrIiVbaaP",
        "outputId": "a05e0d62-0e2c-4336-89e8-795a44e0de61"
      },
      "source": [
        "# print to make sure we have the correct shapes + number of images for training\n",
        "print(\"number of train pictures:\", trainX.shape)\n",
        "print(\"number of trained picture values:\", trainy.shape)\n",
        "# divide by 255 to make [0,255] into [0,1] + print to make sure\n",
        "trainy = tf.keras.utils.to_categorical(trainy,10)\n",
        "testy = tf.keras.utils.to_categorical(testy,10)\n",
        "trainX = trainX/255.0\n",
        "testX = testX/255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of train pictures: (50000, 32, 32, 3)\n",
            "number of trained picture values: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyGXtlI6buS0"
      },
      "source": [
        "_KERAS_BACKEND = keras.backend\n",
        "_KERAS_LAYERS = keras.layers\n",
        "_KERAS_MODELS = keras.models\n",
        "_KERAS_UTILS = keras.utils\n",
        "\n",
        "\n",
        "def get_submodules_from_kwargs(kwargs):\n",
        "    backend = kwargs.get('backend', _KERAS_BACKEND)\n",
        "    layers = kwargs.get('layers', _KERAS_LAYERS)\n",
        "    models = kwargs.get('models', _KERAS_MODELS)\n",
        "    utils = kwargs.get('utils', _KERAS_UTILS)\n",
        "    for key in kwargs.keys():\n",
        "        if key not in ['backend', 'layers', 'models', 'utils']:\n",
        "            raise TypeError('Invalid keyword argument: %s', key)\n",
        "    return backend, layers, models, utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xWMqdM7bzOu",
        "outputId": "705f65d4-246e-41cb-da39-f97590c6468a"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "import keras\n",
        "import keras_applications\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras_applications.imagenet_utils import decode_predictions\n",
        "\n",
        "preprocess_input = keras_applications.imagenet_utils.preprocess_input\n",
        "\n",
        "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                'releases/download/v0.2/'\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                       'releases/download/v0.2/'\n",
        "                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "backend = keras.backend\n",
        "layers = keras.layers\n",
        "models = keras.models\n",
        "keras_utils = keras.utils\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        strides: Strides for the first conv layer in the block.\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3,\n",
        "    the first conv layer at main path is with strides=(2, 2)\n",
        "    And the shortcut should have strides=(2, 2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(\n",
        "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet50(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=1000,\n",
        "             **kwargs):\n",
        "    \"\"\"Instantiates the ResNet50 architecture.\n",
        "    Optionally loads weights pre-trained on ImageNet.\n",
        "    Note that the data format convention used by the model is\n",
        "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
        "    # Arguments\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
        "            or `(3, 224, 224)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 32.\n",
        "            E.g. `(200, 200, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional block.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional block, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "    global backend, layers, models, keras_utils\n",
        "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
        "\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = keras_applications.imagenet_utils._obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=32,\n",
        "                                      data_format=backend.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
        "                          'has been changed since Keras 2.2.0.')\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='resnet50')\n",
        "\n",
        "    # Load weights.\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
        "        else:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "        model.load_weights(weights_path)\n",
        "        if backend.backend() == 'theano':\n",
        "            keras_utils.convert_all_kernels_in_model(model)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg0c_wCJb18h"
      },
      "source": [
        "unquant_resnet = ResNet50(include_top=True, weights=None, input_tensor=None, input_shape=(32,32,3), pooling=None, \n",
        "         classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKBRM1SfpY6g"
      },
      "source": [
        "### Compile unquantized model and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8a_EIhgcTqa"
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "opt = SGD(lr=0.1)\n",
        "# Compile the model\n",
        "unquant_resnet.compile(optimizer=opt, loss=tf.keras.losses.categorical_crossentropy,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztTwH5BagY10",
        "outputId": "b7c85a13-24bf-4e2a-a738-6bbea583542d"
      },
      "source": [
        "history = unquant_resnet.fit(\n",
        "    trainX[:1000],\n",
        "    trainy[:1000],\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    # We pass some validation for\n",
        "    # monitoring validation loss and metrics\n",
        "    # at the end of each epoch\n",
        "    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 8.6944 - accuracy: 0.1213 - val_loss: 133474880.0000 - val_accuracy: 0.0850\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 8.1091 - accuracy: 0.1363 - val_loss: 2569998080.0000 - val_accuracy: 0.0850\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 7.9167 - accuracy: 0.1612 - val_loss: 46416452.0000 - val_accuracy: 0.1250\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 6.9802 - accuracy: 0.1475 - val_loss: 15942241.0000 - val_accuracy: 0.1100\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 6.7769 - accuracy: 0.1550 - val_loss: 18297650.0000 - val_accuracy: 0.1150\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 57s 4s/step - loss: 7.6368 - accuracy: 0.1450 - val_loss: 293683.2812 - val_accuracy: 0.1250\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 57s 4s/step - loss: 5.5507 - accuracy: 0.1637 - val_loss: 167433.8125 - val_accuracy: 0.1050\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 5.2185 - accuracy: 0.1863 - val_loss: 165537.4844 - val_accuracy: 0.1150\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 6.1414 - accuracy: 0.1813 - val_loss: 1901.3916 - val_accuracy: 0.1250\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 5.4915 - accuracy: 0.2375 - val_loss: 354.7072 - val_accuracy: 0.0700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_djvX5OxpeKR"
      },
      "source": [
        "### Display Accuracy (11.20%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO9qffaUiaiO",
        "outputId": "42073e81-30ff-454a-fe6d-6b2f31453b98"
      },
      "source": [
        "score = unquant_resnet.evaluate(testX[:500], testy[:500], verbose=1)\n",
        "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(score[0], score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 2s 143ms/step - loss: 382.4344 - accuracy: 0.1120\n",
            "Test loss 382.4344, accuracy 11.20%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELczl8x5iDqM"
      },
      "source": [
        "### Quantized Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0_kSWRUiZzV"
      },
      "source": [
        "annotate = tfmot.quantization.keras.quantize_annotate_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg9PoRq9ozMo"
      },
      "source": [
        "### Specify Bits of quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGPNQyeTio6f"
      },
      "source": [
        "LastValueQuantizer = tfmot.quantization.keras.quantizers.LastValueQuantizer\n",
        "MovingAverageQuantizer = tfmot.quantization.keras.quantizers.MovingAverageQuantizer\n",
        "\n",
        "\n",
        "class ModifiedDenseQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
        "    def get_weights_and_quantizers(self, layer):\n",
        "      return [(layer.kernel, LastValueQuantizer(num_bits=4, symmetric=True, narrow_range=False, per_axis=False))]\n",
        "\n",
        "    def get_activations_and_quantizers(self, layer):\n",
        "      return [(layer.activation, MovingAverageQuantizer(num_bits=4, symmetric=False, narrow_range=False, per_axis=False))]\n",
        "\n",
        "    def set_quantize_weights(self, layer, quantize_weights):\n",
        "      # Add this line for each item returned in `get_weights_and_quantizers`\n",
        "      # , in the same order\n",
        "      layer.kernel = quantize_weights[0]\n",
        "\n",
        "    def set_quantize_activations(self, layer, quantize_activations):\n",
        "      # Add this line for each item returned in `get_activations_and_quantizers`\n",
        "      # , in the same order.\n",
        "      layer.activation = quantize_activations[0]\n",
        "\n",
        "    # Configure how to quantize outputs (may be equivalent to activations).\n",
        "    def get_output_quantizers(self, layer):\n",
        "      return []\n",
        "\n",
        "    def get_config(self):\n",
        "      return {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KI686s6o_7B"
      },
      "source": [
        "### Quantizing Each layer Individually and returning the Annotated Quantized Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs1l1BqZgxEr"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "import keras\n",
        "import keras_applications\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras_applications.imagenet_utils import decode_predictions\n",
        "\n",
        "preprocess_input = keras_applications.imagenet_utils.preprocess_input\n",
        "\n",
        "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                'releases/download/v0.2/'\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                       'releases/download/v0.2/'\n",
        "                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "backend = keras.backend\n",
        "layers = keras.layers\n",
        "models = keras.models\n",
        "keras_utils = keras.utils\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = annotate(layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a'), quantize_config = ModifiedDenseQuantizeConfig())(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = annotate(layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b'), quantize_config = ModifiedDenseQuantizeConfig())(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = annotate(layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c'), quantize_config = ModifiedDenseQuantizeConfig())(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        strides: Strides for the first conv layer in the block.\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3,\n",
        "    the first conv layer at main path is with strides=(2, 2)\n",
        "    And the shortcut should have strides=(2, 2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = annotate(layers.Conv2D(filters1, (1, 1), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a'), quantize_config = ModifiedDenseQuantizeConfig())(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = annotate(layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b'), quantize_config = ModifiedDenseQuantizeConfig())(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = annotate(layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c'), quantize_config = ModifiedDenseQuantizeConfig())(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = annotate(layers.Conv2D(filters3, (1, 1), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1'), quantize_config = ModifiedDenseQuantizeConfig())(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(\n",
        "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet50(include_top=True,\n",
        "             weights='imagenet',\n",
        "             input_tensor=None,\n",
        "             input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=1000,\n",
        "             **kwargs):\n",
        "    \"\"\"Instantiates the ResNet50 architecture.\n",
        "    Optionally loads weights pre-trained on ImageNet.\n",
        "    Note that the data format convention used by the model is\n",
        "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
        "    # Arguments\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
        "            or `(3, 224, 224)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 32.\n",
        "            E.g. `(200, 200, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional block.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional block, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "    global backend, layers, models, keras_utils\n",
        "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
        "\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = keras_applications.imagenet_utils._obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=32,\n",
        "                                      data_format=backend.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
        "                          'has been changed since Keras 2.2.0.')\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='resnet50')\n",
        "\n",
        "    # Load weights.\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
        "        else:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "        model.load_weights(weights_path)\n",
        "        if backend.backend() == 'theano':\n",
        "            keras_utils.convert_all_kernels_in_model(model)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s452ITBZpDzQ"
      },
      "source": [
        "### Create annotated model instance and make the model quantization aware"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxgGSZePjhnp"
      },
      "source": [
        "quant_resnet = ResNet50(include_top=True, weights=None, input_tensor=None, input_shape=(32,32,3), pooling=None, \n",
        "         classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjswpr-4jfcs"
      },
      "source": [
        "quantize_scope = tfmot.quantization.keras.quantize_scope\n",
        "\n",
        "    # `quantize_apply` requires mentioning `DefaultDenseQuantizeConfig` with `quantize_scope`\n",
        "    # as well as the custom Keras layer.\n",
        "with quantize_scope(\n",
        "{'ModifiedDenseQuantizeConfig':ModifiedDenseQuantizeConfig}):\n",
        "# Use `quantize_apply` to actually make the model quantization aware.\n",
        "  vgg_quant_model = tfmot.quantization.keras.quantize_apply(quant_resnet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM4zRg_spQZz"
      },
      "source": [
        "### Compile and Train quantized model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKO0VcmLlzOG"
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "opt = SGD(lr=0.1)\n",
        "# Compile the model\n",
        "quant_resnet.compile(optimizer=opt, loss=tf.keras.losses.categorical_crossentropy,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EreKH3hyobDB",
        "outputId": "5c741429-d11d-45b9-8a68-c5535a86edde"
      },
      "source": [
        "history = quant_resnet.fit(\n",
        "    trainX[:1000],\n",
        "    trainy[:1000],\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    # We pass some validation for\n",
        "    # monitoring validation loss and metrics\n",
        "    # at the end of each epoch\n",
        "    validation_split=0.2)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(quant_resnet)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - 62s 4s/step - loss: 17.0483 - accuracy: 0.1063 - val_loss: 305509007360.0000 - val_accuracy: 0.0850\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 55s 4s/step - loss: 10.6498 - accuracy: 0.1225 - val_loss: 1358986496.0000 - val_accuracy: 0.0850\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 6.2991 - accuracy: 0.1462 - val_loss: 160909872.0000 - val_accuracy: 0.1050\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 8.7693 - accuracy: 0.1388 - val_loss: 6398166.5000 - val_accuracy: 0.0850\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 10.6385 - accuracy: 0.1538 - val_loss: 18720396.0000 - val_accuracy: 0.0850\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 55s 4s/step - loss: 5.5321 - accuracy: 0.1988 - val_loss: 2848481.5000 - val_accuracy: 0.0850\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 5.7854 - accuracy: 0.1612 - val_loss: 8195201.5000 - val_accuracy: 0.0700\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 6.1976 - accuracy: 0.1437 - val_loss: 1149310.5000 - val_accuracy: 0.0850\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 5.5482 - accuracy: 0.2025 - val_loss: 18670.2676 - val_accuracy: 0.0850\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 5.2840 - accuracy: 0.1900 - val_loss: 464122.2500 - val_accuracy: 0.0700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as res2a_branch2a_layer_call_fn, res2a_branch2a_layer_call_and_return_conditional_losses, res2a_branch2b_layer_call_fn, res2a_branch2b_layer_call_and_return_conditional_losses, res2a_branch2c_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as res2a_branch2a_layer_call_fn, res2a_branch2a_layer_call_and_return_conditional_losses, res2a_branch2b_layer_call_fn, res2a_branch2b_layer_call_and_return_conditional_losses, res2a_branch2c_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmprt_j0sqn/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmprt_j0sqn/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8uEWMKBpT_b"
      },
      "source": [
        "### Display Quantized Model Accuracy (9.40%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW_FIMrkogeS",
        "outputId": "5cc6b3d4-ca1b-45c4-bab7-0a502fd546c9"
      },
      "source": [
        "score = quant_resnet.evaluate(testX[:500], testy[:500], verbose=1)\n",
        "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(score[0], score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 4s 135ms/step - loss: 123.2348 - accuracy: 0.0950\n",
            "Test loss 120.1992, accuracy 9.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTa4PHA7sGSg"
      },
      "source": [
        "### Compare model sizes to ensure quantization has occured\n",
        "- Note that the Unquantized Model is 97.43 MB and the quantized modell is 23.04 MB\n",
        "- 4x decrease in size with 2% decrease in accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGUgQWrDpi2-",
        "outputId": "1a0645b4-a265-4194-90e5-7eeef2cc41cf"
      },
      "source": [
        "import tempfile\n",
        "model = ResNet50()\n",
        "# Create float TFLite model.\n",
        "unquant_resnet = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "unquant_resnet = unquant_resnet.convert()\n",
        "print('converted')\n",
        "# Measure sizes of models.\n",
        "_, float_file = tempfile.mkstemp('.tflite')\n",
        "_, quant_file = tempfile.mkstemp('.tflite')\n",
        "print('files')\n",
        "with open(quant_file, 'wb') as f:\n",
        "  f.write(quantized_tflite_model)\n",
        "print('done')\n",
        "with open(float_file, 'wb') as f:\n",
        "  f.write(unquant_resnet)\n",
        "\n",
        "print(\"Float model in Mb:\", os.path.getsize(float_file) / float(2**20))\n",
        "print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102858752/102853048 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as res2a_branch2a_layer_call_fn, res2a_branch2a_layer_call_and_return_conditional_losses, res2a_branch2b_layer_call_fn, res2a_branch2b_layer_call_and_return_conditional_losses, res2a_branch2c_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as res2a_branch2a_layer_call_fn, res2a_branch2a_layer_call_and_return_conditional_losses, res2a_branch2b_layer_call_fn, res2a_branch2b_layer_call_and_return_conditional_losses, res2a_branch2c_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp_tr2q6dp/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp_tr2q6dp/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "converted\n",
            "files\n",
            "done\n",
            "Float model in Mb: 97.43069076538086\n",
            "Quantized model in Mb: 23.042282104492188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TQXy38NsDXa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}