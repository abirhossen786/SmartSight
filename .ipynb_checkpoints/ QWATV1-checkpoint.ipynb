{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structural-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input\n",
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-scoop",
   "metadata": {},
   "source": [
    "### Loading CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "several-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainy), (testX, testy) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "productive-enlargement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train pictures: (50000, 32, 32, 3)\n",
      "number of trained picture values: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# print to make sure we have the correct shapes + number of images for training\n",
    "print(\"number of train pictures:\", trainX.shape)\n",
    "print(\"number of trained picture values:\", trainy.shape)\n",
    "# divide by 255 to make [0,255] into [0,1] + print to make sure!\n",
    "trainy = tf.keras.utils.to_categorical(trainy,10)\n",
    "testy = tf.keras.utils.to_categorical(testy,10)\n",
    "trainX = trainX/255.0\n",
    "testX = testX/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-bible",
   "metadata": {},
   "source": [
    "### VGG-16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "simple-windows",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# example of loading the vgg16 model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# load model\n",
    "model = VGG16()\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-phase",
   "metadata": {},
   "source": [
    "### VGG-16 Clone Without Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "leading-vinyl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 33,638,218\n",
      "Trainable params: 33,638,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_wq = tf.keras.Sequential()\n",
    "#block-1\n",
    "model_wq.add(Conv2D(input_shape=(32,32,3),\n",
    "                    filters=64,kernel_size=(3,3),\n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block1_conv1'))\n",
    "model_wq.add(Dropout(0.3))\n",
    "model_wq.add(Conv2D(filters=64,\n",
    "                    kernel_size=(3,3),\n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block1_conv2'))\n",
    "model_wq.add(Dropout(0.4))\n",
    "model_wq.add(MaxPool2D(pool_size=(2,2), strides=(2,2), name='block1_pool'))\n",
    "\n",
    "\n",
    "#block-2\n",
    "model_wq.add(Conv2D(filters=128, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block2_conv1'))\n",
    "model_wq.add(Dropout(0.4))\n",
    "model_wq.add(Conv2D(filters=128, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block2_conv2'))\n",
    "model_wq.add(Dropout(0.4))\n",
    "model_wq.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block2_pool'))\n",
    "\n",
    "#block-3\n",
    "model_wq.add(Conv2D(filters=256, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block3_conv1'))\n",
    "model_wq.add(Dropout(0.4))\n",
    "model_wq.add(Conv2D(filters=256, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block3_conv2'))\n",
    "model_wq.add(Dropout(0.4))\n",
    "model_wq.add(Conv2D(filters=256, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block3_conv3'))\n",
    "model_wq.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block3_pool'))\n",
    "\n",
    "#block-4\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block4_conv1'))\n",
    "model_wq.add(Dropout(0.4))\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block4_conv2'))\n",
    "model_wq.add(Dropout(0.4))\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block4_conv3'))\n",
    "model_wq.add(Dropout(0.4))\n",
    "model_wq.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block4_pool'))\n",
    "\n",
    "#block-5\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block5_conv1'))\n",
    "model_wq.add(Dropout(0.4))\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block5_conv2'))\n",
    "model_wq.add(Dropout(0.4))\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block5_conv3'))\n",
    "model_wq.add(Dropout(0.3))\n",
    "model_wq.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block5_pool'))\n",
    "\n",
    "\n",
    "#fc1, fc2 and predictions\n",
    "model_wq.add(Dropout(0.5))\n",
    "model_wq.add(Flatten(name='flatten'))\n",
    "model_wq.add(Dense(units=4096,activation=\"relu\",name='fc1'))\n",
    "model_wq.add(Dense(units=4096,activation=\"relu\",name='fc2'))\n",
    "\n",
    "model_wq.add(Dropout(0.5))\n",
    "model_wq.add(Dense(units=10, activation=\"softmax\",name='predictions'))\n",
    "\n",
    "model_wq.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-federation",
   "metadata": {},
   "source": [
    "### Tranining withgout quantization vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "democratic-anime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "800/800 [==============================] - 2335s 3s/step - loss: 2.2990 - accuracy: 0.1084 - val_loss: 2.3031 - val_accuracy: 0.1016\n",
      "Epoch 2/15\n",
      "800/800 [==============================] - 2973s 4s/step - loss: 2.3035 - accuracy: 0.0980 - val_loss: 2.3028 - val_accuracy: 0.1025\n",
      "Epoch 3/15\n",
      "800/800 [==============================] - 1757s 2s/step - loss: 2.3033 - accuracy: 0.1008 - val_loss: 2.3049 - val_accuracy: 0.0980\n",
      "Epoch 4/15\n",
      "800/800 [==============================] - 2215s 3s/step - loss: 2.3037 - accuracy: 0.0985 - val_loss: 2.3033 - val_accuracy: 0.0980\n",
      "Epoch 5/15\n",
      "800/800 [==============================] - 1811s 2s/step - loss: 2.3034 - accuracy: 0.1005 - val_loss: 2.3034 - val_accuracy: 0.1022\n",
      "Epoch 6/15\n",
      "800/800 [==============================] - 2098s 3s/step - loss: 2.3032 - accuracy: 0.0974 - val_loss: 2.3033 - val_accuracy: 0.0952\n",
      "Epoch 7/15\n",
      "800/800 [==============================] - 2130s 3s/step - loss: 2.3032 - accuracy: 0.0958 - val_loss: 2.3026 - val_accuracy: 0.1014\n",
      "Epoch 8/15\n",
      "800/800 [==============================] - 28330s 35s/step - loss: 2.3034 - accuracy: 0.0964 - val_loss: 2.3033 - val_accuracy: 0.0952\n",
      "Epoch 9/15\n",
      "800/800 [==============================] - 2574s 3s/step - loss: 2.3032 - accuracy: 0.0981 - val_loss: 2.3034 - val_accuracy: 0.0952\n",
      "Epoch 10/15\n",
      "800/800 [==============================] - 1894s 2s/step - loss: 2.3033 - accuracy: 0.0990 - val_loss: 2.3033 - val_accuracy: 0.1003\n",
      "Epoch 11/15\n",
      "800/800 [==============================] - 2376s 3s/step - loss: 2.3029 - accuracy: 0.1011 - val_loss: 2.3033 - val_accuracy: 0.0980\n",
      "Epoch 12/15\n",
      "800/800 [==============================] - 1676s 2s/step - loss: 2.3030 - accuracy: 0.0979 - val_loss: 2.3032 - val_accuracy: 0.0980\n",
      "Epoch 13/15\n",
      "800/800 [==============================] - 1807s 2s/step - loss: 2.3032 - accuracy: 0.0997 - val_loss: 2.3030 - val_accuracy: 0.1016\n",
      "Epoch 14/15\n",
      "800/800 [==============================] - 1986s 2s/step - loss: 2.3032 - accuracy: 0.0999 - val_loss: 2.3028 - val_accuracy: 0.1016\n",
      "Epoch 15/15\n",
      "800/800 [==============================] - 1984s 2s/step - loss: 2.3032 - accuracy: 0.0985 - val_loss: 2.3036 - val_accuracy: 0.0980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10f66b580>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "opt = SGD(lr=0.1)\n",
    "# Compile the model\n",
    "model_wq.compile(optimizer=opt, loss=tf.keras.losses.categorical_crossentropy,metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "model_wq.fit(trainX, trainy,\n",
    "          batch_size=50,\n",
    "          epochs=15,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-throw",
   "metadata": {},
   "source": [
    "### Loss and Accuracy without quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "banner-manor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 78s 248ms/step - loss: 2.3033 - accuracy: 0.1000\n",
      "Test loss 2.3033, accuracy 10.00%\n"
     ]
    }
   ],
   "source": [
    "score = model_wq.evaluate(testX, testy, verbose=1)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(score[0], score[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-roberts",
   "metadata": {},
   "source": [
    "### Defining the quantization config\n",
    "`DefaultDenseQuantizeConfig` is 8 bit\n",
    "\n",
    "`ModifiedDenseQuantizeConfig` is 4 bit\n",
    "\n",
    "`UltraDenseQuantizeConfig` is 2 bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "special-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "LastValueQuantizer = tfmot.quantization.keras.quantizers.LastValueQuantizer\n",
    "MovingAverageQuantizer = tfmot.quantization.keras.quantizers.MovingAverageQuantizer\n",
    "\n",
    "class DefaultDenseQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
    "    # Configure how to quantize weights.\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "      return [(layer.kernel, LastValueQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    # Configure how to quantize activations.\n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "      return [(layer.activation, MovingAverageQuantizer(num_bits=8, symmetric=False, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "      # Add this line for each item returned in `get_weights_and_quantizers`\n",
    "      # , in the same order\n",
    "      layer.kernel = quantize_weights[0]\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "      # Add this line for each item returned in `get_activations_and_quantizers`\n",
    "      # , in the same order.\n",
    "      layer.activation = quantize_activations[0]\n",
    "\n",
    "    # Configure how to quantize outputs (may be equivalent to activations).\n",
    "    def get_output_quantizers(self, layer):\n",
    "      return []\n",
    "\n",
    "    def get_config(self):\n",
    "      return {}\n",
    "\n",
    "class ModifiedDenseQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "      return [(layer.kernel, LastValueQuantizer(num_bits=4, symmetric=True, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "      return [(layer.activation, MovingAverageQuantizer(num_bits=4, symmetric=False, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "      # Add this line for each item returned in `get_weights_and_quantizers`\n",
    "      # , in the same order\n",
    "      layer.kernel = quantize_weights[0]\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "      # Add this line for each item returned in `get_activations_and_quantizers`\n",
    "      # , in the same order.\n",
    "      layer.activation = quantize_activations[0]\n",
    "\n",
    "    # Configure how to quantize outputs (may be equivalent to activations).\n",
    "    def get_output_quantizers(self, layer):\n",
    "      return []\n",
    "\n",
    "    def get_config(self):\n",
    "      return {}\n",
    "\n",
    "class UltraDenseQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "      return [(layer.kernel, LastValueQuantizer(num_bits=2, symmetric=True, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "      return [(layer.activation, MovingAverageQuantizer(num_bits=2, symmetric=False, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "      # Add this line for each item returned in `get_weights_and_quantizers`\n",
    "      # , in the same order\n",
    "      layer.kernel = quantize_weights[0]\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "      # Add this line for each item returned in `get_activations_and_quantizers`\n",
    "      # , in the same order.\n",
    "      layer.activation = quantize_activations[0]\n",
    "\n",
    "    # Configure how to quantize outputs (may be equivalent to activations).\n",
    "    def get_output_quantizers(self, layer):\n",
    "      return []\n",
    "\n",
    "    def get_config(self):\n",
    "      return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-webmaster",
   "metadata": {},
   "source": [
    "### Quantizing vgg-16\n",
    "`ModifiedDenseQuantizeConfig` is 4 bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bound-campaign",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quantize_annotate (QuantizeA (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_1 (Quantiz (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_2 (Quantiz (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_3 (Quantiz (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_4 (Quantiz (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_5 (Quantiz (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_6 (Quantiz (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_7 (Quantiz (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_8 (Quantiz (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_9 (Quantiz (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_10 (Quanti (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_11 (Quanti (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_12 (Quanti (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_13 (Quanti (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_14 (Quanti (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "quantize_annotate_15 (Quanti (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 33,638,218\n",
      "Trainable params: 33,638,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "annotate = tfmot.quantization.keras.quantize_annotate_layer\n",
    "\n",
    "quant_vgg16 = tf.keras.Sequential()\n",
    "    # Only annotated layers will be quantized\n",
    "    \n",
    "#block-1\n",
    "quant_vgg16.add(annotate(Conv2D(input_shape=(32,32,3),\n",
    "                    filters=64,kernel_size=(3,3),\n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block1_conv1'), quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.3))   \n",
    "\n",
    "quant_vgg16.add(annotate(Conv2D(filters=64,\n",
    "                    kernel_size=(3,3),\n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block1_conv2'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(MaxPool2D(pool_size=(2,2), strides=(2,2), name='block1_pool'))\n",
    "\n",
    "\n",
    "#block-2\n",
    "quant_vgg16.add(annotate(Conv2D(filters=128, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block2_conv1'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(annotate(Conv2D(filters=128, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block2_conv2'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block2_pool'))\n",
    "\n",
    "#block-3\n",
    "quant_vgg16.add(annotate(Conv2D(filters=256, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block3_conv1'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(annotate(Conv2D(filters=256, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block3_conv2'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(annotate(Conv2D(filters=256, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block3_conv3'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block3_pool'))\n",
    "\n",
    "#block-4\n",
    "quant_vgg16.add(annotate(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block4_conv1'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(annotate(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block4_conv2'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(annotate(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block4_conv3'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block4_pool'))\n",
    "\n",
    "#block-5\n",
    "quant_vgg16.add(annotate(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block5_conv1'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(annotate(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block5_conv2'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(annotate(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block5_conv3'),\n",
    "                    quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dropout(0.4))\n",
    "quant_vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block5_pool'))\n",
    "\n",
    "#fc1, fc2 and predictions\n",
    "quant_vgg16.add(Dropout(0.5))\n",
    "quant_vgg16.add(annotate(Flatten(name='flatten')))\n",
    "quant_vgg16.add(annotate(Dense(units=4096,activation=\"relu\",name='fc1'), quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "\n",
    "quant_vgg16.add(Dropout(0.5))\n",
    "quant_vgg16.add(annotate(Dense(units=4096,activation=\"relu\",name='fc2'), quantize_config=ModifiedDenseQuantizeConfig()))\n",
    "quant_vgg16.add(Dense(units=10, activation=\"softmax\",name='predictions'))    \n",
    "  \n",
    "\n",
    "quantize_scope = tfmot.quantization.keras.quantize_scope\n",
    "\n",
    "# `quantize_apply` requires mentioning `DefaultDenseQuantizeConfig` with `quantize_scope`\n",
    "# as well as the custom Keras layer.\n",
    "with quantize_scope(\n",
    "  {'DefaultDenseQuantizeConfig': DefaultDenseQuantizeConfig,\n",
    "  'ModifiedDenseQuantizeConfig':ModifiedDenseQuantizeConfig,\n",
    "  'UltraDenseQuantizeConfig':UltraDenseQuantizeConfig}):\n",
    "  # Use `quantize_apply` to actually make the model quantization aware.\n",
    "  vgg_quant_model = tfmot.quantization.keras.quantize_apply(quant_vgg16)\n",
    "    \n",
    "quant_vgg16.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "consecutive-period",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "800/800 [==============================] - 1945s 2s/step - loss: 2.2992 - accuracy: 0.1071 - val_loss: 2.3036 - val_accuracy: 0.0997\n",
      "Epoch 2/15\n",
      "800/800 [==============================] - 2062s 3s/step - loss: 2.3036 - accuracy: 0.0971 - val_loss: 2.3035 - val_accuracy: 0.0952\n",
      "Epoch 3/15\n",
      "800/800 [==============================] - 2436s 3s/step - loss: 2.3034 - accuracy: 0.1030 - val_loss: 2.3033 - val_accuracy: 0.0997\n",
      "Epoch 4/15\n",
      "800/800 [==============================] - 2237s 3s/step - loss: 2.3034 - accuracy: 0.1010 - val_loss: 2.3034 - val_accuracy: 0.1025\n",
      "Epoch 5/15\n",
      "800/800 [==============================] - 2455s 3s/step - loss: 2.3035 - accuracy: 0.1008 - val_loss: 2.3029 - val_accuracy: 0.1016\n",
      "Epoch 6/15\n",
      "800/800 [==============================] - 1991s 2s/step - loss: 2.3035 - accuracy: 0.0963 - val_loss: 2.3033 - val_accuracy: 0.0997\n",
      "Epoch 7/15\n",
      "800/800 [==============================] - 2023s 3s/step - loss: 2.3031 - accuracy: 0.1002 - val_loss: 2.3034 - val_accuracy: 0.1003\n",
      "Epoch 8/15\n",
      "800/800 [==============================] - 2258s 3s/step - loss: 2.3032 - accuracy: 0.0981 - val_loss: 2.3034 - val_accuracy: 0.0977\n",
      "Epoch 9/15\n",
      "800/800 [==============================] - 2261s 3s/step - loss: 2.3031 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.1014\n",
      "Epoch 10/15\n",
      "800/800 [==============================] - 1735s 2s/step - loss: 2.3032 - accuracy: 0.1021 - val_loss: 2.3027 - val_accuracy: 0.1014\n",
      "Epoch 11/15\n",
      "800/800 [==============================] - 1725s 2s/step - loss: 2.3032 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1025\n",
      "Epoch 12/15\n",
      "800/800 [==============================] - 1718s 2s/step - loss: 2.3034 - accuracy: 0.0978 - val_loss: 2.3029 - val_accuracy: 0.0952\n",
      "Epoch 13/15\n",
      "800/800 [==============================] - 1553s 2s/step - loss: 2.3029 - accuracy: 0.1006 - val_loss: 2.3031 - val_accuracy: 0.1014\n",
      "Epoch 14/15\n",
      "800/800 [==============================] - 1987s 2s/step - loss: 2.3031 - accuracy: 0.0974 - val_loss: 2.3037 - val_accuracy: 0.0952\n",
      "Epoch 15/15\n",
      "800/800 [==============================] - 1962s 2s/step - loss: 2.3031 - accuracy: 0.1000 - val_loss: 2.3032 - val_accuracy: 0.0952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block1_conv1_layer_call_fn, block1_conv1_layer_call_and_return_conditional_losses, block1_conv2_layer_call_fn, block1_conv2_layer_call_and_return_conditional_losses, block2_conv1_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as block1_conv1_layer_call_fn, block1_conv1_layer_call_and_return_conditional_losses, block1_conv2_layer_call_fn, block1_conv2_layer_call_and_return_conditional_losses, block2_conv1_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1q/ns7tqnvx55lfc3nl7vf90tth0000gn/T/tmp2xhx82j8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1q/ns7tqnvx55lfc3nl7vf90tth0000gn/T/tmp2xhx82j8/assets\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "opt = SGD(lr=0.1)\n",
    "# Compile the model\n",
    "quant_vgg16.compile(optimizer=opt, loss=tf.keras.losses.categorical_crossentropy,metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "quant_vgg16.fit(trainX, trainy,\n",
    "          batch_size=50,\n",
    "          epochs=15,\n",
    "          validation_split=0.2)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(quant_vgg16)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-uncle",
   "metadata": {},
   "source": [
    "### Loss and Accuracy with quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fourth-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 50s 159ms/step - loss: 2.3029 - accuracy: 0.1000\n",
      "Test loss 2.3029, accuracy 10.00%\n"
     ]
    }
   ],
   "source": [
    "quant_score = quant_vgg16.evaluate(testX, testy, verbose=1)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(score[0], score[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-spyware",
   "metadata": {},
   "source": [
    "### Quantization vs Without quantization Test loss\n",
    "#### note that the model without quantization is 528 MB and the quantized model is 32 MB (16x decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "patent-statement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1q/ns7tqnvx55lfc3nl7vf90tth0000gn/T/tmpdricefb_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1q/ns7tqnvx55lfc3nl7vf90tth0000gn/T/tmpdricefb_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted\n",
      "files\n",
      "done\n",
      "Float model in Mb: 527.8010864257812\n",
      "Quantized model in Mb: 32.207611083984375\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "# Create float TFLite model.\n",
    "model_wq = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "model_wq = model_wq.convert()\n",
    "print('converted')\n",
    "# Measure sizes of models.\n",
    "_, float_file = tempfile.mkstemp('.tflite')\n",
    "_, quant_file = tempfile.mkstemp('.tflite')\n",
    "print('files')\n",
    "with open(quant_file, 'wb') as f:\n",
    "  f.write(quantized_tflite_model)\n",
    "print('done')\n",
    "with open(float_file, 'wb') as f:\n",
    "  f.write(model_wq)\n",
    "\n",
    "print(\"Float model in Mb:\", os.path.getsize(float_file) / float(2**20))\n",
    "print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-criterion",
   "metadata": {},
   "source": [
    "## Evaluate the test loss for quantized and unquantized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "narrow-december",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss for quantized model is  2.3028557300567627\n",
      "Test loss for normal (unquantized) model is  2.3028557300567627\n",
      "Percent change in quantized model test loss and normal model test loss is  0.0 %\n"
     ]
    }
   ],
   "source": [
    "print('Test loss for quantized model is ',quant_score[0])\n",
    "print('Test loss for normal (unquantized) model is ',score[0])\n",
    "quant_percent = (quant_score[0] - score[0])/ score[0]\n",
    "print('Percent change in quantized model test loss and normal model test loss is ', quant_percent, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-iceland",
   "metadata": {},
   "source": [
    "## Save quantized model to upload on microcontroller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "banner-disability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33772128"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"cifar_quant.tflite\", \"wb\").write(quantized_tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
