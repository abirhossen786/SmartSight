{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structural-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, BatchNormalization\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-scoop",
   "metadata": {},
   "source": [
    "### Loading CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "several-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainy), (testX, testy) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "productive-enlargement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train pictures: (50000, 32, 32, 3)\n",
      "number of trained picture values: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# print to make sure we have the correct shapes + number of images for training\n",
    "print(\"number of train pictures:\", trainX.shape)\n",
    "print(\"number of trained picture values:\", trainy.shape)\n",
    "# divide by 255 to make [0,255] into [0,1] + print to make sure!\n",
    "trainy = tf.keras.utils.to_categorical(trainy,10)\n",
    "testy = tf.keras.utils.to_categorical(testy,10)\n",
    "trainX = trainX/255.0\n",
    "testX = testX/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-phase",
   "metadata": {},
   "source": [
    "### VGG-16 Clone Without Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "leading-vinyl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 15,001,418\n",
      "Trainable params: 14,991,946\n",
      "Non-trainable params: 9,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_wq = tf.keras.Sequential()\n",
    "#block-1\n",
    "model_wq.add(Conv2D(input_shape=(32,32,3),\n",
    "                    filters=64,kernel_size=(3,3),\n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block1_conv1'))\n",
    "model_wq.add(BatchNormalization())\n",
    "model_wq.add(Dropout(0.3))\n",
    "\n",
    "model_wq.add(Conv2D(filters=64,\n",
    "                    kernel_size=(3,3),\n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block1_conv2'))\n",
    "model_wq.add(BatchNormalization())\n",
    "\n",
    "model_wq.add(MaxPool2D(pool_size=(2,2), strides=(2,2), name='block1_pool'))\n",
    "\n",
    "\n",
    "#block-2\n",
    "model_wq.add(Conv2D(filters=128, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block2_conv1'))\n",
    "model_wq.add(BatchNormalization())\n",
    "model_wq.add(Dropout(0.4))\n",
    "\n",
    "model_wq.add(Conv2D(filters=128, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block2_conv2'))\n",
    "model_wq.add(BatchNormalization())\n",
    "\n",
    "model_wq.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block2_pool'))\n",
    "\n",
    "#block-3\n",
    "model_wq.add(Conv2D(filters=256, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block3_conv1'))\n",
    "model_wq.add(BatchNormalization())\n",
    "model_wq.add(Dropout(0.4))\n",
    "\n",
    "model_wq.add(Conv2D(filters=256, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block3_conv2'))\n",
    "model_wq.add(BatchNormalization())\n",
    "model_wq.add(Dropout(0.4))\n",
    "\n",
    "model_wq.add(Conv2D(filters=256, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block3_conv3'))\n",
    "model_wq.add(BatchNormalization())\n",
    "\n",
    "model_wq.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block3_pool'))\n",
    "\n",
    "#block-4\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block4_conv1'))\n",
    "model_wq.add(BatchNormalization())\n",
    "model_wq.add(Dropout(0.4))\n",
    "\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block4_conv2'))\n",
    "model_wq.add(BatchNormalization())\n",
    "model_wq.add(Dropout(0.4))\n",
    "\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block4_conv3'))\n",
    "model_wq.add(BatchNormalization())\n",
    "\n",
    "model_wq.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block4_pool'))\n",
    "\n",
    "#block-5\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block5_conv1'))\n",
    "model_wq.add(BatchNormalization())\n",
    "model_wq.add(Dropout(0.4))\n",
    "\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block5_conv2'))\n",
    "model_wq.add(BatchNormalization())\n",
    "model_wq.add(Dropout(0.4))\n",
    "\n",
    "model_wq.add(Conv2D(filters=512, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding=\"same\", \n",
    "                    activation=\"relu\",\n",
    "                    name='block5_conv3'))\n",
    "model_wq.add(BatchNormalization())\n",
    "\n",
    "model_wq.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='block5_pool'))\n",
    "\n",
    "\n",
    "#fc1, fc2 and predictions\n",
    "model_wq.add(Dropout(0.5))\n",
    "model_wq.add(Flatten(name='flatten'))\n",
    "model_wq.add(Dense(units=512,activation=\"relu\",name='fc1'))\n",
    "model_wq.add(BatchNormalization())\n",
    "\n",
    "model_wq.add(Dropout(0.5))\n",
    "model_wq.add(Dense(units=10, activation=\"softmax\",name='predictions'))\n",
    "\n",
    "model_wq.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-federation",
   "metadata": {},
   "source": [
    "### Tranining withgout quantization vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "democratic-anime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 13s 12ms/step - loss: 2.6187 - accuracy: 0.1730 - val_loss: 6.4007 - val_accuracy: 0.0971\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.9199 - accuracy: 0.2528 - val_loss: 6.2614 - val_accuracy: 0.1107\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.8065 - accuracy: 0.2902 - val_loss: 2.9115 - val_accuracy: 0.1690\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.7293 - accuracy: 0.3243 - val_loss: 2.1482 - val_accuracy: 0.2536\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.6506 - accuracy: 0.3663 - val_loss: 2.3405 - val_accuracy: 0.2739\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.5854 - accuracy: 0.4024 - val_loss: 2.5533 - val_accuracy: 0.2721\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.4847 - accuracy: 0.4517 - val_loss: 2.0361 - val_accuracy: 0.4126\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.3841 - accuracy: 0.5015 - val_loss: 2.3047 - val_accuracy: 0.4211\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.2921 - accuracy: 0.5361 - val_loss: 3.1144 - val_accuracy: 0.4057\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.2206 - accuracy: 0.5673 - val_loss: 2.9062 - val_accuracy: 0.5213\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.1563 - accuracy: 0.5979 - val_loss: 1.3765 - val_accuracy: 0.5821\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.1066 - accuracy: 0.6128 - val_loss: 1.5432 - val_accuracy: 0.5929\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.0532 - accuracy: 0.6339 - val_loss: 1.2321 - val_accuracy: 0.6067\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 1.0110 - accuracy: 0.6481 - val_loss: 1.2311 - val_accuracy: 0.6095\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.9788 - accuracy: 0.6606 - val_loss: 1.3077 - val_accuracy: 0.6150\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.9324 - accuracy: 0.6800 - val_loss: 1.3604 - val_accuracy: 0.6257\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.9035 - accuracy: 0.6935 - val_loss: 1.2111 - val_accuracy: 0.6690\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.8712 - accuracy: 0.7032 - val_loss: 1.1033 - val_accuracy: 0.6689\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.8406 - accuracy: 0.7145 - val_loss: 1.0222 - val_accuracy: 0.6851\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.8106 - accuracy: 0.7242 - val_loss: 1.0125 - val_accuracy: 0.6951\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.7896 - accuracy: 0.7349 - val_loss: 1.0928 - val_accuracy: 0.6963\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.7600 - accuracy: 0.7462 - val_loss: 0.8818 - val_accuracy: 0.7294\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.7392 - accuracy: 0.7499 - val_loss: 1.0159 - val_accuracy: 0.7027\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.7288 - accuracy: 0.7579 - val_loss: 0.7986 - val_accuracy: 0.7563\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.7000 - accuracy: 0.7669 - val_loss: 0.8812 - val_accuracy: 0.7172\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.6781 - accuracy: 0.7742 - val_loss: 0.9784 - val_accuracy: 0.7349\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.6639 - accuracy: 0.7807 - val_loss: 0.9655 - val_accuracy: 0.7360\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.6476 - accuracy: 0.7851 - val_loss: 0.9540 - val_accuracy: 0.7276\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.6230 - accuracy: 0.7945 - val_loss: 0.7643 - val_accuracy: 0.7756\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.6062 - accuracy: 0.8022 - val_loss: 0.8468 - val_accuracy: 0.7555\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.6047 - accuracy: 0.8004 - val_loss: 0.8474 - val_accuracy: 0.7602\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.5800 - accuracy: 0.8084 - val_loss: 0.7450 - val_accuracy: 0.7672\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.5855 - accuracy: 0.8064 - val_loss: 0.7371 - val_accuracy: 0.7809\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.5508 - accuracy: 0.8192 - val_loss: 0.8470 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.5349 - accuracy: 0.8258 - val_loss: 0.7095 - val_accuracy: 0.7886\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.5233 - accuracy: 0.8287 - val_loss: 0.8257 - val_accuracy: 0.7686\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.5001 - accuracy: 0.8356 - val_loss: 0.6799 - val_accuracy: 0.7928\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.4940 - accuracy: 0.8375 - val_loss: 0.7630 - val_accuracy: 0.7944\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.4806 - accuracy: 0.8413 - val_loss: 0.8502 - val_accuracy: 0.7709\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.4736 - accuracy: 0.8457 - val_loss: 0.7194 - val_accuracy: 0.7874\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.4587 - accuracy: 0.8508 - val_loss: 0.7959 - val_accuracy: 0.7797\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.4464 - accuracy: 0.8546 - val_loss: 0.6733 - val_accuracy: 0.8014\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.4369 - accuracy: 0.8584 - val_loss: 0.7110 - val_accuracy: 0.7947\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.4194 - accuracy: 0.8627 - val_loss: 0.6874 - val_accuracy: 0.7998\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.4074 - accuracy: 0.8683 - val_loss: 0.7456 - val_accuracy: 0.7982\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.4008 - accuracy: 0.8696 - val_loss: 0.6857 - val_accuracy: 0.8068\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3841 - accuracy: 0.8729 - val_loss: 0.7138 - val_accuracy: 0.7921\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3812 - accuracy: 0.8757 - val_loss: 0.6869 - val_accuracy: 0.8022\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3777 - accuracy: 0.8761 - val_loss: 0.6316 - val_accuracy: 0.8163\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3546 - accuracy: 0.8841 - val_loss: 0.7170 - val_accuracy: 0.8119\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3467 - accuracy: 0.8877 - val_loss: 0.6308 - val_accuracy: 0.8240\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3429 - accuracy: 0.8888 - val_loss: 0.6835 - val_accuracy: 0.8101\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3458 - accuracy: 0.8890 - val_loss: 0.5877 - val_accuracy: 0.8303\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3294 - accuracy: 0.8919 - val_loss: 0.7807 - val_accuracy: 0.7941\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3119 - accuracy: 0.9002 - val_loss: 0.7110 - val_accuracy: 0.8089\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3113 - accuracy: 0.8989 - val_loss: 0.6789 - val_accuracy: 0.8186\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.3002 - accuracy: 0.9024 - val_loss: 0.6802 - val_accuracy: 0.8250\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2913 - accuracy: 0.9068 - val_loss: 0.7070 - val_accuracy: 0.8180\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2889 - accuracy: 0.9061 - val_loss: 0.7088 - val_accuracy: 0.8172\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2747 - accuracy: 0.9099 - val_loss: 0.6971 - val_accuracy: 0.8146\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2762 - accuracy: 0.9105 - val_loss: 0.6707 - val_accuracy: 0.8239\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2657 - accuracy: 0.9117 - val_loss: 0.7394 - val_accuracy: 0.8165\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2667 - accuracy: 0.9129 - val_loss: 0.6516 - val_accuracy: 0.8314\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2529 - accuracy: 0.9168 - val_loss: 0.7431 - val_accuracy: 0.8146\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2534 - accuracy: 0.9185 - val_loss: 0.6917 - val_accuracy: 0.8263\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2488 - accuracy: 0.9215 - val_loss: 0.6833 - val_accuracy: 0.8279\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2294 - accuracy: 0.9265 - val_loss: 0.7269 - val_accuracy: 0.8211\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2387 - accuracy: 0.9239 - val_loss: 0.7118 - val_accuracy: 0.8260\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2281 - accuracy: 0.9265 - val_loss: 0.6620 - val_accuracy: 0.8327\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2188 - accuracy: 0.9291 - val_loss: 0.7358 - val_accuracy: 0.8191\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2131 - accuracy: 0.9306 - val_loss: 0.6718 - val_accuracy: 0.8306\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2102 - accuracy: 0.9318 - val_loss: 0.7687 - val_accuracy: 0.8283\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2052 - accuracy: 0.9329 - val_loss: 0.7243 - val_accuracy: 0.8284\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1988 - accuracy: 0.9366 - val_loss: 0.7833 - val_accuracy: 0.8185\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.2008 - accuracy: 0.9364 - val_loss: 0.7010 - val_accuracy: 0.8265\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1927 - accuracy: 0.9385 - val_loss: 0.7206 - val_accuracy: 0.8208\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1911 - accuracy: 0.9391 - val_loss: 0.7387 - val_accuracy: 0.8269\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1853 - accuracy: 0.9407 - val_loss: 0.7426 - val_accuracy: 0.8261\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1850 - accuracy: 0.9415 - val_loss: 0.7180 - val_accuracy: 0.8307\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1763 - accuracy: 0.9449 - val_loss: 0.7474 - val_accuracy: 0.8284\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1714 - accuracy: 0.9447 - val_loss: 0.7177 - val_accuracy: 0.8341\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1705 - accuracy: 0.9457 - val_loss: 0.7593 - val_accuracy: 0.8295\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1667 - accuracy: 0.9468 - val_loss: 0.6839 - val_accuracy: 0.8405\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1647 - accuracy: 0.9471 - val_loss: 0.7717 - val_accuracy: 0.8292\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1570 - accuracy: 0.9493 - val_loss: 0.7113 - val_accuracy: 0.8352\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1570 - accuracy: 0.9498 - val_loss: 0.7276 - val_accuracy: 0.8328\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1551 - accuracy: 0.9513 - val_loss: 0.6999 - val_accuracy: 0.8347\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1523 - accuracy: 0.9507 - val_loss: 0.6971 - val_accuracy: 0.8401\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1517 - accuracy: 0.9520 - val_loss: 0.7714 - val_accuracy: 0.8274\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1465 - accuracy: 0.9542 - val_loss: 0.7189 - val_accuracy: 0.8353\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1433 - accuracy: 0.9543 - val_loss: 0.7502 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1425 - accuracy: 0.9546 - val_loss: 0.8597 - val_accuracy: 0.8138\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1376 - accuracy: 0.9570 - val_loss: 0.7081 - val_accuracy: 0.8415\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1333 - accuracy: 0.9577 - val_loss: 0.8169 - val_accuracy: 0.8292\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1275 - accuracy: 0.9593 - val_loss: 0.7265 - val_accuracy: 0.8373\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1232 - accuracy: 0.9606 - val_loss: 0.8039 - val_accuracy: 0.8326\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1292 - accuracy: 0.9590 - val_loss: 0.7219 - val_accuracy: 0.8434\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1278 - accuracy: 0.9600 - val_loss: 0.7187 - val_accuracy: 0.8399\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1230 - accuracy: 0.9610 - val_loss: 0.7250 - val_accuracy: 0.8457\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.1162 - accuracy: 0.9629 - val_loss: 0.6878 - val_accuracy: 0.8482\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-87df10f7de4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           validation_split=0.2)\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifar10vgg_nonquant.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "opt = SGD(learning_rate=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Compile the model\n",
    "model_wq.compile(optimizer=opt, loss=tf.keras.losses.categorical_crossentropy,metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "model_wq.fit(trainX, trainy,\n",
    "          batch_size=50,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)\n",
    "model.save_weights('cifar10vgg_nonquant.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6acbf646",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wq.save_weights('cifar10vgg_nonquant.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-throw",
   "metadata": {},
   "source": [
    "### Loss and Accuracy without quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "banner-manor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.7216 - accuracy: 0.8418\n",
      "Test loss 0.7216, accuracy 84.18%\n"
     ]
    }
   ],
   "source": [
    "score = model_wq.evaluate(testX, testy, verbose=1)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(score[0], score[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-spyware",
   "metadata": {},
   "source": [
    "### Quantization vs Without quantization Test loss\n",
    "#### note that the model without quantization is 528 MB and the quantized model is 32 MB (16x decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "patent-statement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1q/ns7tqnvx55lfc3nl7vf90tth0000gn/T/tmpdricefb_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1q/ns7tqnvx55lfc3nl7vf90tth0000gn/T/tmpdricefb_/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted\n",
      "files\n",
      "done\n",
      "Float model in Mb: 527.8010864257812\n",
      "Quantized model in Mb: 32.207611083984375\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "# Create float TFLite model.\n",
    "model_wq = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "model_wq = model_wq.convert()\n",
    "print('converted')\n",
    "# Measure sizes of models.\n",
    "_, float_file = tempfile.mkstemp('.tflite')\n",
    "_, quant_file = tempfile.mkstemp('.tflite')\n",
    "print('files')\n",
    "with open(quant_file, 'wb') as f:\n",
    "  f.write(quantized_tflite_model)\n",
    "print('done')\n",
    "with open(float_file, 'wb') as f:\n",
    "  f.write(model_wq)\n",
    "\n",
    "print(\"Float model in Mb:\", os.path.getsize(float_file) / float(2**20))\n",
    "print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-iceland",
   "metadata": {},
   "source": [
    "## Save quantized model to upload on microcontroller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "banner-disability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33772128"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"cifar_quant.tflite\", \"wb\").write(quantized_tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
